{"384": {"change_type": ["add"], "section_title": "Study 1 - Classroom Demonstration", "text_before": "", "author": "01989413042403575936", "section_id": 7, "change_extent": 1.0, "focus": 0, "api": 0.017857142857142856, "par_id": 384, "authors": "Na", "prox_focus": 0.073715260299840185, "text_after": "It is evident that students developed the feelings of ownership of the demonstrations during participating in the experiments, generating the results, and analyzing their own data. They were not only more engaged in this activity, they also saw actual learning gains from the activity. For example, they felt that they ``better understand what was talked about in the reading\u2019\u2019, ``remember what was taught in that week better\u2019\u2019, and got inspired to create their own experiments(e.g. ``we were thinking of ideas for the final project, all of our ideas came from the class demonstrations. Like \u2018Oh remember when Professor [anonymized] did this, or remember when he did that\u2019\u2019\u2019.), etc. Comparing to demonstrations that showed students results, some demonstrations that didn\u2019t show any results did not show the learning gains. For example, retention was worse, ``You normally remember what you answered, but sometimes he\u2019ll send an experiment over the weekend and then we didn\u2019t see the results until the following week. You kind of forgot what you reported.\u2019\u2019\n", "prox_user": 0.0}, "2": {"change_type": ["edit"], "section_title": "abstract", "text_before": "\\keywords{classroom demonstrations; engagement; self-determination theory; grounded theory; learning}", "author": "01989413042403575936", "section_id": 0, "change_extent": 0.71174048635821652, "focus": 0, "api": 0.18622448979591835, "par_id": 2, "authors": "Na", "prox_focus": 0.020761301653917669, "text_after": "\\keywords{hands-on learning; social science education; grounded theory; educational technology}", "prox_user": 0.01055990814525346}, "387": {"change_type": ["add"], "section_title": "Introduction", "text_before": "", "author": "01989413042403575936", "section_id": 1, "change_extent": 1.0, "focus": 0, "api": 0.03571428571428571, "par_id": 387, "authors": "Na", "prox_focus": 0.29999999999995386, "text_after": "\\section{Introduction}\n", "prox_user": 0.0}, "388": {"change_type": ["add", "edit"], "section_title": "\\textbf{Reasons of engaging in classroom demonstrations}", "text_before": "", "author": "01989413042403575936", "section_id": 10, "change_extent": 1, "focus": 0, "api": 0.01020408163265306, "par_id": 388, "authors": "Na", "prox_focus": 0.10164982739479071, "text_after": "More than half of the students could identify the unique hands-on values provided by classroom demonstrations. For example, \\textit{``I think being able to do the study ourselves allows us to experience first hand what anyone else taking the experiment will experience. So understanding how someone does the study and thinking more about what a study should look like when you design it. Because you experience it first hand.\u2019\u2019}\n \nStudents could naturally engage in the activity because the contents were interesting and the unpredictable results stimulated curiosity. For example, \\textit{``It was fun and everyone was giggling. The class feeling like all involved and laughing. \u2026 It was cool and I liked it because I actually wasn\u2019t able to predict what they were doing.\u2019\u2019} Related to this point, several students also mentioned that the activity engaged everybody, therefore it provides additional opportunity to socialize with peers, and then the active classroom environment in turn reinforce engagement of everyone. For example, \\textit{``We can see what our classmates are thinking and maybe remember what we were thinking and how that compares to our classmates. I think it builds a different, really different classroom environment, I think it kinds of changes the energy in the class. Also, it changes sort of the quality and quantity of what is being shared by people. So it\u2019s nice because we hear from a lot of different people, which is kind of rare in a lecture class.\u201d}", "prox_user": 0.0}, "389": {"change_type": ["add", "edit"], "section_title": "\\textbf{Reasons of engaging in classroom demonstrations}", "text_before": "", "author": "01989413042403575936", "section_id": 10, "change_extent": 1, "focus": 0, "api": 0.01020408163265306, "par_id": 389, "authors": "Na", "prox_focus": 0.099593305354549633, "text_after": "More interestingly, almost half of the students reflected deeper thoughts about the pedagogical value of classroom demonstrations - real world applicability. They recognized and appreciated that their instructors altered the experiments so that it was more relevant to them. It inspired them how they could make variations of the contents or the variables of the experiments to test questions relevant and interested to them. For example, \\textit{``I think that it all goes back to he makes it really applicable to the real world and really lets us think about how it is applicable to things that we care about. By introducing the experiments and asking us to design our own experiments in the final project, he really helps inspiring us. And by doing that he makes us all more engaged because it makes it more fun to have a bit of an experiment. And then see how it plays out, and then I think also we are able to have a small piece of evidence either for or against a theory.\u2019\u2019} Related to this point, several students of one course linked classroom demonstrations and their final projects (similar in the form of several lab sessions), coined the final projects as \\textit{``the tangible outcomes\u2019\u2019} of their learning of the classroom demonstrations. And because of the foreseeable tangible outcomes (the final projects), students effortfully engaged in active thinking about real world application while participating in classroom demonstration.\n*\n\\begin{table}\n\\begin{tabular}{ | p{0.3\\linewidth} | p{0.2\\linewidth} | p{0.4\\linewidth} |}\n\\hline\n\\textbf{Reason} & \\textbf{Percentage} & \\textbf{Definition} \\\\ \\hline\nFun & 31\\% & Interesting contents, unpredictable or surprising results. \\\\ \\hline\nHands-on skills & 54\\% & Acquiring hands-on skills, such as checking the look and feel and the workflow of experiments, checking experiment design from participant viewpoint. \\\\ \\hline\nReal world applicability & 46\\% & Contents and experiment designs that are applicable to one\u2019s own interest. \\\\ \\hline\nSocial interaction & 8\\% & Opportunities to share and interact with peers. \\\\ \\hline\nChanging mode & 31\\% & Breaking the monotony of a long lecture. \\\\ \\hline\n\\end{tabular}\n\\caption{Five reasons of engaging in classroom demonstrations}~\\label{tab:reasonsofengaging}\n\\end{table}\n", "prox_user": 0.0}, "265": {"change_type": ["edit", "edit", "edit"], "section_title": "Common themes of engaging in classroom demonstrations", "text_before": "\\begin{quote}\nI thought it was interesting how we took [an experiment], instead of just reading a paper on results from it. I think it was interesting that we performed the experiment ourselves and not only did we ask other people to take the survey we did it ourselves. I think having done the experiment, it helped me find ways to create my own experiment. So I\u2019ve taken some aspects of that one and sort of applied it to what I am thinking of doing with my experiment which is a lot harder to get that just from a paper. So again if I had just read a paper and the results of the study that we did, I would have more difficulty coming up with my idea for the project and knowing how I should make the faces cropped and grayscaled and blurred slightly and how I might be able to get results from - or what kind of questions to ask people in having designed it. So if I had just read the paper I would have to spend a lot more time thinking of how I want to.---Student 2 (from psychology class)\n\\end{quote}", "author": "01989413042403575936", "section_id": 11, "change_extent": 0.62306282789604639, "focus": 0, "api": 0.22448979591836732, "par_id": 265, "authors": "Na", "prox_focus": 0.0076733197579799519, "text_after": "\\subsubsection{Common themes of engaging in classroom demonstrations}\n\\subsubsection{Participant experience and data ownership}\nFeelings of ownership emerged as a potentially significant element of engagement in classroom demonstrations of social science classes. When talking about their experience with classroom demonstrations, especially the experiments that students participated, students often described it as they themselves ``recreated it in class\u2019\u2019. Interestingly, some of these students who also had prior experience with biology class demos or computer science class demos described those demos as they ``just sit there and watched\u2019\u2019 or ``just followed the instructions\u2019\u2019. What students really recreated was the phenomena, which is the \\textbf{results} of the experiments (the experiments themselves were recreated by instructors). Not like in biology demos or computer science demos where the results were predictable and consistent, these results generated by each student as participant in the experiment were personal, idiosyncratic, and sometimes disturbing. Students said, ``we have to see our results\u2019\u2019, ``we got to anticipate our results\u2019\u2019, ``analyzing our data was very helpful\u2019\u2019. To students, seeing data from the papers were less relevant to them, quoting a student talking about analyzing data from a paper, ``You\u2019re just given the data, it\u2019s just going through the same analytical process.\u2019\u2019", "prox_user": 0.10251389244004759}, "312": {"change_type": ["add", "edit", "edit"], "section_title": "Inconsistent results and social group", "text_before": "", "author": "01989413042403575936", "section_id": 9, "change_extent": 1, "focus": 0, "api": 0.20918367346938774, "par_id": 312, "authors": "Na", "prox_focus": 0.0061953787388927062, "text_after": "\\textbf{Implication:} Supporting data ownership is critical to the success of classroom demonstration. Not like natural science demos, the phenomena of social science demos are often not so obvious to students. Providing the results helped students link their subject experiences to some tangible outcomes. Once students had their results, they were eager to examine what the results meant, how the results were produced, why there was these results rather than other possible outcomes, in a nutshell, they engaged in active learning led by their strong association with the data.", "prox_user": 0.0023044169733032406}, "order": [317, 2, 387, 318, 319, 320, 334, 337, 338, 339, 340, 341, 342, 343, 321, 322, 344, 251, 347, 388, 389, 265, 384, 349, 353, 354, 356, 312, 358, 360, 361, 362, 363, 364, 366, 367, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 333], "317": {"change_type": ["add"], "section_title": "abstract", "text_before": "", "author": "01989413042403575936", "section_id": 0, "change_extent": 1.0, "focus": 0, "api": 0.028061224489795915, "par_id": 317, "authors": "Na", "prox_focus": 0.10814369110984022, "text_after": "\\begin{abstract}\n \\end{abstract}", "prox_user": 0.0}, "318": {"change_type": ["add", "edit"], "section_title": "Background and Motivation", "text_before": "", "author": "01989413042403575936", "section_id": 2, "change_extent": 1, "focus": 0, "api": 0.05357142857142857, "par_id": 318, "authors": "Na", "prox_focus": 0.15763768096453956, "text_after": "\\subsection{Background and Motivation}\nHands-on learning is an important part in STEM education. Instructors regularly provide classroom demonstrations and laboratory sessions, where students can experience and execute knowledge. Broadly speaking, hands-on curriculum serves at least two important learning goals: 1) Technical skills that are practical and useful for STEM careers, including use of specialized equipment, measurement techniques, mathematics applied to real-world physical/mechanical problems, etc. and 2) Cognitive skills that generalize to new empirical domains, including experimental logic and design, and the ability to critically evaluate empirical evidence and make sound inferences. While hands-on learning is essential for a highly skilled technical workforce, the generalizable cognitive skills of hands-on learning are additionally beneficial in many social science fields: e.g. optimizing workplace efficiency and deployment of human resources, designing user-friendly technology, creating data-driven approaches to improve education, increasing the efficacy of public health campaigns, studying and optimizing decision making, etc. ", "prox_user": 0.0}, "319": {"change_type": ["add"], "section_title": "Introduction", "text_before": "", "author": "01989413042403575936", "section_id": 1, "change_extent": 1.0, "focus": 0, "api": 0.028061224489795915, "par_id": 319, "authors": "Na", "prox_focus": 0.10814369110984022, "text_after": "Like natural sciences and engineering, social sciences empirically study real world phenomena, frequently using sophisticated quantitative methods. Unlike in natural sciences and engineering, however, undergraduate students in social sciences get little chance to experience hands-on learning. For example, a 2013 White Paper from the American Psychological Association (APA) showed that only 6\\% of the institutions of higher learning surveyed had laboratory experiences in any of their psychology courses (APA Board of Educational Affairs Working Group, 2013). In most cases, students learn empirical studies and research methods only through papers and lectures.", "prox_user": 0.0}, "320": {"change_type": ["add", "edit", "edit"], "section_title": "Background and Motivation", "text_before": "", "author": "01989413042403575936", "section_id": 2, "change_extent": 1, "focus": 0, "api": 0.05357142857142857, "par_id": 320, "authors": "Na", "prox_focus": 0.16919903694247285, "text_after": "The recent trend of online experiments provide huge potentials to support hands-on learning in social science classrooms, if they are carefully designed. Many research projects provide well-made online experiments that can be adapted for classroom demonstrations. Online experiment authoring tools can be used for laboratory sessions to support students designing their own experiments. Social networks make subject recruitment easy for students. So the resources are abundant but scattered all over the Internet. It is not clear how they are organized and altered to use in social science classrooms. There is also no evidence that what pedagogical values they provide. Given the rare regular practice of hands-on learning in social science classes and the ad-hoc adaptation of existing resources, we think that there is a need for a better designed learning system to support hands-on learning in social science, so that our students can enjoy the same benefit that their natural science peers once obtained from regularly conducted hands-on demos and labs. As HCI researchers, instructors, and practitioners in the field, we think that understanding user needs, the socio-technical situations, and the design space for hands-on learning systems are at least as, or even more, important than designing the system itself, otherwise we could just reinvent the wheels. Reflecting on this belief, our design process addressed the following goals: \\textbf{(a)} understand the current practice and limitations of demos and labs as well as students and instructors\u2019 needs in social science classes. \\textbf{(b)} understand the activity sequences, mechanisms, and pedagogical values of demos and labs in the literature (mostly in natural science education). \\textbf{(c)} make informed design choices based on these understandings. \\textbf{(d)} make formal evaluation of the design. This paper presents the hands-on learning system TELLab (The Experiential Learning Lab), and knowledge gained through the design of the system. ", "prox_user": 0.0}, "321": {"change_type": ["add", "edit"], "section_title": "Summary", "text_before": "", "author": "01989413042403575936", "section_id": 6, "change_extent": 1, "focus": 0, "api": 0.05357142857142857, "par_id": 321, "authors": "Na", "prox_focus": 0.20401168542025749, "text_after": "\\subsubsection{Summary}\nWhether we can blindly apply our knowledge about natural science hands-on learning to the social science domain is unclear. We think that there are at least two different characters in social science hands-on learning: \\textbf{(1)} students have to serve as subjects during demonstrations, and then examine the results as experimenters. This dual role of students is different than natural sciences, in which students are always observers and the subjects are always other objects or creatures. \\textbf{(2)} the results of many social science experiments can not be reliably reproduced in class with small and nonrepresentative samples (such as a class of college students) due to individual differences and noisy measurements. This is different than rolling some objects down an inclined plane, for which the result is almost always definitive and visible to everyone.", "prox_user": 0.0}, "322": {"change_type": ["add", "edit", "edit", "edit", "edit"], "section_title": "Summary", "text_before": "", "author": "01989413042403575936", "section_id": 6, "change_extent": 1, "focus": 0, "api": 0.07397959183673469, "par_id": 322, "authors": "Na", "prox_focus": 0.16414148644472867, "text_after": "To summarize, there are considerable technologies and contents available and some theoretical support to suggest that hands-on learning can be a valuable component in social science education. We do not expect the technologies and contents themselves to be sufficient to support hands-on learning. The tools and contents are not originally designed for educational purpose, and there has not been research studying how they are used, what their effects are in terms of learning, and what their limitations are in the educational context. The theoretical work in natural science laid out the best practice of presenting classroom demonstrations. We don\u2019t expect it to work the same way in social sciences, given that students have to experience the experiment themselves and their results may be inconsistent. Our working hypothesis is that students will engage even more than students experiencing natural science demos. We also expect that the knowledge obtained as being participants in the classroom demonstrations can transfer to a new context, where students apply that knowledge to design their own experiments. To our knowledge, there is no evidence showing the pedagogical practice and its value of using online experiments and tools in social science education. This paper presents our work to identify these pedagogies, then design a system to support them, and finally evaluate their value in real classrooms.", "prox_user": 0.0}, "333": {"change_type": ["add", "edit"], "section_title": "Case Study", "text_before": "", "author": "01989413042403575936", "section_id": 13, "change_extent": 1, "focus": 0, "api": 0.033163265306122444, "par_id": 333, "authors": "Na", "prox_focus": 0.028378918977551654, "text_after": "\\section{Case Study}\nConfirmation inquiry - analyze data\nGuided inquiry - replication\nOpen inquiry - new questions\nStudent attitude, engagement, performance from Justin\u2019s classes", "prox_user": 0.0}, "334": {"change_type": ["add", "edit", "edit", "edit", "edit"], "section_title": "Background and Motivation", "text_before": "", "author": "01989413042403575936", "section_id": 2, "change_extent": 1, "focus": 0, "api": 0.18622448979591835, "par_id": 334, "authors": "Na", "prox_focus": 0.1606308911903146, "text_after": "To summarize, this paper has three contributions:\n\\begin{enumerate}\n\\item We contribute system design and APIs to a learning platform to support \\textbf{classroom demonstration} and \\textbf{inquiry-based lab} in social science classrooms. This platform, named TELLab, provide various types (e.g. survey, reaction-time, interactive game) of behavioral experiments for students to participate and create.\n\\item We propose design implications and examples to support critical pedagogies that we identified in classroom demonstration and inquiry-based lab: \\textbf{feelings of ownership}, \\textbf{cognitive disequilibrium and restore}, and \\textbf{learning with variable guides}.  \n\\item We suggest a set of TELLab-supported activities that other instructors can adopt and adapt in their courses. Our case study of one instructor\u2019s use of TELLab in two different courses shows that TELLab is flexible for different teaching purposes. And our end-of-semester questionnaire shows that the use of TELLab truly benefit engagement and learning for social science students.\n\\end{enumerate}\n", "prox_user": 0.0}, "337": {"change_type": ["edit"], "section_title": "Introduction", "text_before": "\\section{Related Work}\nIn this paper, we refine the use of hands-on learning to refer to classroom demonstrations and inquiry-based labs, which are the two most suitable candidates for social science learning among other forms of hands-on learning. In this section, we review prior work related to this two types of hands-on learning, mostly in natural science domains. We also review existing technologies that can be adapted to support this two types of hands-on learning in social science classrooms. These works provide an initial grounding for the design of TELLab.\n", "author": "01989413042403575936", "section_id": 1, "change_extent": 0.58153525365471892, "focus": 0, "api": 0.03571428571428571, "par_id": 337, "authors": "Na", "prox_focus": 0.36473566713149774, "text_after": "\\subsection{Related Work}\nFirst and foremost, our work is based on an understanding of classroom demonstration literature and inquiry-based lab literature, which are previously mostly relevant to natural science education. We chose to study demonstration and lab because they are the essential forms of hands-on activities in teacher training~\\cite{niess2005preparing}, so supporting these two activities will likely benefit the majority teachers. Besides, both classroom demonstration and lab are studied extensively in the literature and both have shown pedagogical values in various subject matters, which are described in detail below. On the other hand, technologies that support demonstration and lab are very specific to subject domains (e.g. physics and biology simulation lab can take very different forms), yet are rare in social science domains. We will discuss the possibilities of altering existing technologies for demonstration and lab use respectively. These understandings provide a basis for designing social science hands-on learning systems.\n", "prox_user": 0.0}, "338": {"change_type": ["edit", "edit"], "section_title": "Classroom Demonstration", "text_before": "\\subsection{Classroom Demonstration and Technologies}\nResearch indicates that performing classroom demonstration in certain sequence is particularly effective for learning. The sequence is summarized as the (P)redict, (O)bserve, (E)xplain model~\\cite{white1994conceptual}, by which students (1) predict the outcome of a demonstration; (2) observe the demonstration; and (3) explain the outcome. Compared to simply presenting a demonstration in class, applying the POE sequence can reduce misconceptions~\\cite{crouch2004classroom, miller2013role} and enhance test performance~\\cite{schwartz1998time}. ", "author": "01989413042403575936", "section_id": 4, "change_extent": 0.27435560862096442, "focus": 0, "api": 0.03571428571428571, "par_id": 338, "authors": "Na", "prox_focus": 0.32691417117498328, "text_after": "\\subsubsection{Classroom Demonstration}\nIn the literature of natural science education, it has been demonstrated repeatedly that presenting classroom demonstrations in the sequence of (P)rediction, (O)bservation and (E)xplanation (known as the POE model) yield positive learning outcomes~\\cite{crouch2004classroom, miller2013role, schwartz1998time}. In particular, students first predict the outcome of a demonstration, and then observe the demonstration, and finally the instructor explain the outcome and lead a discussion. Compared to simply presenting a demonstration in class, applying the POE model can reduce misconceptions~\\cite{crouch2004classroom, miller2013role} and enhance test performance~\\cite{schwartz1998time}. ", "prox_user": 0.0}, "339": {"change_type": ["edit"], "section_title": "Introduction", "text_before": "It is not clear yet why the two additional steps, Prediction and Explanation, yield better learning. \nContradictory results from some other classroom demonstration studies showed that when there were discrepancies between expected results and actual results, students actually experienced confusion, frustration and subsequently boredom during learning~\\cite{roth1997may}. In a synthesized review of affective states in learning, D\u2019Mello and colleagues proposed a model of affect dynamics~\\cite{d2012dynamics}. The model posits that engagement is built upon a cognitive equilibrium state. When this equilibrium is interrupted, surprise or confusion occurs, and there is a demand to seek to restore the cognitive equilibrium. If the disequilibrium is not resolved, learners get stuck and eventually disengage from learning. If the disequilibrium is resolved, learners get back to an engagement state. In a following work, D\u2019Mello found that brief cognitive disequilibrium state could even benefit learning given that cognitive equilibrium could be restored successfully~\\cite{d2014confusion}, learners who were made confused during learning demonstrated better cognitive skills in the posttest quiz. In natural science classroom demonstrations, instructors often deliberately introduce cognitive disequilibrium as an instructional strategy to stimulate deep learning. The way it was done was often through introducing anomalous data, however a large body of work showed that this strategy did not work~\\cite{limon2001cognitive}. Instructors reported that the anomalous data was not meaningful to students~\\cite{baddock2008effectiveness}, ``students could not have experienced the intended conflict\u2019\u2019, ``the intended conflict was only accessible indirectly\u2019\u2019. In social science classroom demonstrations, we expect that cognitive conflict is unavoidable because of individual differences and errors in measurements, students may often experience surprise and confusion when they encounter unpredictable inconsistent results. However, it can be an effective strategy for social science instructors, given that the anomalous data are actually generated by students, students will be well aware of it if there is discrepancy between their results and expected results of the experiments. ", "author": "01989413042403575936", "section_id": 1, "change_extent": 0.011075328687286556, "focus": 0, "api": 0.03571428571428571, "par_id": 339, "authors": "Na", "prox_focus": 0.30042294491068944, "text_after": "It is not clear yet why the two additional steps, Prediction and Explanation, yield better learning. \nContradictory results from some other classroom demonstration studies showed that when there were discrepancies between expected results and actual results, students actually experienced confusion, frustration and subsequently boredom during learning~\\cite{roth1997may}. In a synthesized review of affective states in learning, D\u2019Mello and colleagues proposed a model of affect dynamics~\\cite{d2012dynamics}. The model posits that engagement is built upon a cognitive equilibrium state. When this equilibrium is interrupted, surprise or confusion occurs, and there is a demand to seek to restore the cognitive equilibrium. If the disequilibrium is not resolved, learners get stuck and eventually disengage from learning. If the disequilibrium is resolved, learners get back to an engagement state. In a following work, D\u2019Mello found that brief cognitive disequilibrium state could even benefit learning given that cognitive equilibrium could be restored successfully~\\cite{d2014confusion}, learners who were made confused during learning demonstrated better cognitive skills in the posttest quiz. In natural science classroom demonstrations, instructors often deliberately introduce cognitive disequilibrium as an instructional strategy to stimulate deep learning. The way it was done was often through introducing anomalous data, it is possible that prediction and explanation facilitates this strategy by stimulating attention to unexpected results and resolving the disturbed mind eventually. However a large body of work showed that this strategy did not work~\\cite{limon2001cognitive}. Instructors reported that the anomalous data was not meaningful to students~\\cite{baddock2008effectiveness}, ``students could not have experienced the intended conflict\u2019\u2019, ``the intended conflict was only accessible indirectly\u2019\u2019. However, in social science classroom demonstrations, we expect that cognitive conflict is unavoidable because of individual differences and errors in measurements, students may often experience surprise and confusion when they encounter unpredictable inconsistent results. However, it can be an effective strategy for social science instructors, given that the anomalous data are actually generated by students, students will be well aware of it if there is discrepancy between their results and expected results of the experiments. ", "prox_user": 0.0}, "340": {"change_type": ["edit"], "section_title": "Introduction", "text_before": "Online experiments that provide participants with meaningful feedback on their results are suitable for classroom demonstrations. For example, many instructors use the ProjectImplicit website (projectimplicit.harvard.edu) to teach prejudice and implicit association test (IAT), which is a measurement to test prejudice. The website currently holds about 10 IATs, students can take any of the 10 IATs online, and see a score representing their prejudice or bias toward a social issue at the end of the test. Similar websites such as TestMyBrain (testmybrain.org) and LabInTheWild (labinthewild.org) provide a range of cognitive tests(i.e. memory, perception, attention, etc.) for people to participate and see their scores at the end of the tests. These website not only provide individual scores but also statistics of all the past scores, therefore providing opportunities for students to compare results and confront with discrepancies between their results and others\u2019.\n", "author": "01989413042403575936", "section_id": 1, "change_extent": 0.0085604545159889689, "focus": 0, "api": 0.03571428571428571, "par_id": 340, "authors": "Na", "prox_focus": 0.3003137556382976, "text_after": "\\textbf{Technology:} Online experiments that provide participants with meaningful feedback on their results are suitable for classroom demonstrations. For example, many instructors use the ProjectImplicit website (projectimplicit.harvard.edu) to teach prejudice and implicit association test (IAT), which is a measurement to test prejudice. The website currently holds 10 IATs, students can take any of the 10 IATs online, and see a score representing their prejudice or bias toward a social issue at the end of the test. Similar websites such as TestMyBrain (testmybrain.org) and LabInTheWild (labinthewild.org) provide a range of cognitive tests(i.e. memory, perception, attention, etc.) for people to participate and see their scores at the end of the tests. These website not only provide individual scores but also statistics of all the past scores, therefore providing opportunities for students to compare results and confront with discrepancies between their results and others\u2019.\n", "prox_user": 0.0}, "341": {"change_type": ["add", "edit"], "section_title": "Inquiry-based Lab", "text_before": "", "author": "01989413042403575936", "section_id": 5, "change_extent": 1, "focus": 0, "api": 0.11479591836734693, "par_id": 341, "authors": "Na", "prox_focus": 0.056931799591112643, "text_after": "\\subsubsection{Inquiry-based Lab}\nLab provides a tangible way for students to apply their knowledge. Different than classroom demonstrations where students act as subjects and observers, in labs, students take the role similar to researchers. Lab provide students the environment and instruction to practice scientific inquiry, from which they develop the ability to ``ask questions, plan and conduct investigations, use appropriate tools and techniques to gather data, think critically and logically about relationships between evidence and explanations, construct and analyze alternative explanations, and communicate scientific arguments\u2019\u2019 (NRC 1996, P.105).", "prox_user": 0.012841787583728179}, "342": {"change_type": ["add", "edit"], "section_title": "Inquiry-based Lab", "text_before": "", "author": "01989413042403575936", "section_id": 5, "change_extent": 1, "focus": 0, "api": 0.11479591836734693, "par_id": 342, "authors": "Na", "prox_focus": 0.10845720102775558, "text_after": "Students cannot simply transfer what they read about science to conduct science. There needs scaffolding procedure to prepare students with the necessary technical and cognitive skills. It is suggested that the inquiry activity evolve from confined simple tasks to more open-ended complex tasks (NRC 2000, p. 29). Many science instructors follow a four-level model of inquiry, the four levels are: confirmation, structured inquiry, guided inquiry, and open inquiry (Rezba, Auldridge, and Rhea, 1999). In confirmation, students confirm a principle through an activity in which the results are known in advance. In structured inquiry, students investigate a teacher-presented question through a prescribed procedure. In guided inquiry, students investigate a teacher-presented question using student designed/selected procedures. In open inquiry, students investigate topic-related questions that are student formulated through student designed/selected procedures. Further along the thought of learning transfer, there is a lack of research on whether students can transfer what they experience in a science phenomenon to science inquiry, in other words, whether knowledge gained through classroom demonstrations can be applied in inquiry-based lab. We think that it is possible, given that the two activities share similar forms, for example, both require observation and hands-on examination of a phenomenon. What is different between the two activities is the level of cognitive and technical skills involved. While classroom demonstration requires active thinking about the phenomenon, inquiry-based lab requires constructive thinking and collaboration, which requires additional cognitive skills to plan and actually produce the phenomenon~\\cite{chi2009active}. It is not clear how much and what knowledge can be transferred from classroom demonstration to inquiry-based lab, and how can we design technology to support the transfer benefit, if there is any. We explore this question in one of our studies, which is to be discussed in study 2.", "prox_user": 0.012633439876301193}, "343": {"change_type": ["add", "edit"], "section_title": "Inquiry-based Lab", "text_before": "", "author": "01989413042403575936", "section_id": 5, "change_extent": 1, "focus": 0, "api": 0.11479591836734693, "par_id": 343, "authors": "Na", "prox_focus": 0.062578703991336346, "text_after": "\\textbf{Technology:} Online experiment authoring tools provide students the opportunity to conduct scientific inquiry. Survey tools such as Qualtrics (qualtrics.com) and Google Forms (google.com/forms/) are flexible to support all levels of inquiry. For example, in a confined inquiry process, students can replicate instructors\u2019 experiments or make variations of instructors\u2019 experiments, in an open-ended process, students can build their own experiment from scratch. \n", "prox_user": 0.012813705953330002}, "344": {"change_type": ["add", "edit", "edit"], "section_title": "Study 1 - Classroom Demonstration", "text_before": "", "author": "01989413042403575936", "section_id": 7, "change_extent": 1, "focus": 0, "api": 0.1020408163265306, "par_id": 344, "authors": "Na", "prox_focus": 0.042603027558193965, "text_after": "\\section{Study 1 - Classroom Demonstration}\nTo study the use of classroom demonstration use in social science courses, we implemented 17 classroom demonstrations in three very different courses at [university name anonymized] (i.e. a cognitive research course, a political science course, and a HCI design course). For survey type of experiments, we use Qualtrics and Google Forms. For many cognitive experiments, they often contain highly interactive game-like tasks and require millisecond accuracy in recording reaction time, so we customly built these experiments ourselves. In this study, we aim to understand classroom demonstration, including its current practice and limitations, activity sequences, mechanisms, and pedagogical values. We use the findings to inform the design of TELLab\u2019s experiment participation portal.\n", "prox_user": 0.012180790670506548}, "347": {"change_type": ["add"], "section_title": "Study 1 - Classroom Demonstration", "text_before": "", "author": "01989413042403575936", "section_id": 7, "change_extent": 1.0, "focus": 0, "api": 0.02551020408163265, "par_id": 347, "authors": "Na", "prox_focus": 0.029356757657269212, "text_after": "\\subsection{Results}\n", "prox_user": 0.0}, "349": {"change_type": ["add", "edit", "edit", "edit"], "section_title": "Inconsistent results and social group", "text_before": "", "author": "01989413042403575936", "section_id": 9, "change_extent": 1, "focus": 0, "api": 0.04591836734693877, "par_id": 349, "authors": "Na", "prox_focus": 0.032806832133977983, "text_after": "\\subsubsection{Inconsistent results and social group}\nInconsistent results occurred very often in our social science demos. We identified three sets of results that students frequently mentioned, individual results, aggregated results of the whole class, and results reported in original papers. We observed that discrepancy could occur between all combinations of the three sets of results, we also observed discrepancy between student expected results and the three sets of results. Given that discrepancy occur so frequent and in complex ways, surprise and confusion occurred very often at the same time.", "prox_user": 0.0}, "353": {"change_type": ["add", "edit"], "section_title": "Inconsistent results and social group", "text_before": "", "author": "01989413042403575936", "section_id": 9, "change_extent": 1, "focus": 0, "api": 0.02040816326530612, "par_id": 353, "authors": "Na", "prox_focus": 0.047563678236250156, "text_after": "Consistent with D\u2019Mello\u2019s affect dynamics model, we found that students actively searched for agreement of their results as a way of resolving cognitive disequilibrium. We identified three sources for finding agreement:\n\\begin{enumerate}\n\\item \\textbf{past experience:} students\u2019 past experiences agree with students\u2019 individual results\n\\item \\textbf{social group:} the class aggregated results agree with students\u2019 individual results\n\\item \\textbf{literature:} the results reported in original papers agree with students\u2019 individual results\n\\end{enumerate}", "prox_user": 0.0}, "354": {"change_type": ["add", "edit"], "section_title": "Inconsistent results and social group", "text_before": "", "author": "01989413042403575936", "section_id": 9, "change_extent": 1, "focus": 0, "api": 0.02040816326530612, "par_id": 354, "authors": "Na", "prox_focus": 0.045615031785936372, "text_after": "We found that although the three sources all led students back to cognitive equilibrium, they did not work equally well. Social group seemed to be the most credible source for students, if students\u2019 individual results agree with their class\u2019 aggregated results, students were very satisfied with it, demonstrating a relief from the cognitive disequilibrium before. Students\u2019 own past experiences were also credible sources, we observed that students often used their past experience or knowledge to explain their results. To our surprise, the results from the literature seemed to be the least credible sources. Students seemed indifference rather than satisfied when their results agreed with the literature. And when discrepancy occurred, students often trusted the other two type of results than results from the literature.", "prox_user": 0.0}, "379": {"change_type": ["add"], "section_title": "TELLab", "text_before": "", "author": "01989413042403575936", "section_id": 18, "change_extent": 1.0, "focus": 0, "api": 0.012755102040816325, "par_id": 379, "authors": "Na", "prox_focus": 0.055129219774371734, "text_after": "\\subsection{Designing experiment templates}\nSuppose an instructor wants to use TELLab, but she can not use the existing experiment templates to build her experiment. She probably can code her own experiment, and then set up a backend server and database, and acquire a domain to hold all the codes. Using TELLab, she only need to code the minimal distinct part of her experiment and upload it as a new experiment template. Then she can freely use and even combine any experiment template to build her experiment in TELLab\u2019s GUI interface. And her experiment will be available online, and she can collect data which will be stored in TELLab\u2019s database. The new template will be available to all TELLab users, so her students and even other instructors and their students can benefit from these user-built templates.", "prox_user": 0.0}, "356": {"change_type": ["add"], "section_title": "Study 1 - Classroom Demonstration", "text_before": "", "author": "01989413042403575936", "section_id": 7, "change_extent": 1.0, "focus": 0, "api": 0.02040816326530612, "par_id": 356, "authors": "Na", "prox_focus": 0.039748442644439122, "text_after": "The dominant role of past experience and social group is a double sword, when they are consistent with the results from the literature, they enhanced students\u2019 engagement in learning and thinking about the new knowledge (i.e. a theory, principle, model or method derived from the experiments in that literature), when they are inconsistent with the results from the literature, students tended to distrust the new knowledge. For example, ``He tested social dominance theory, like males are more dominant than females, but in our class we found women are more dominant than men. We didn\u2019t prove that theory.\u2019\u2019 In another classroom demonstration, it was the similar case, but the instructor carefully led students to think about flaws in the classroom demonstration rather than thinking about flaws in the theory. In this case, although students still seemed skeptical, they developed viable options to retest the theory: ``I don\u2019t know why we were so off, and we came up with a few things that were kind of necessary for it to work, and we saw how that might not have occurred.\u2019\u2019 Had the students have the opportunity to revise the experiment and retest the theory, their attitude may be changed.", "prox_user": 0.0}, "358": {"change_type": ["add", "edit"], "section_title": "Study 2 - Inquiry-based Lab", "text_before": "", "author": "01989413042403575936", "section_id": 10, "change_extent": 1, "focus": 0, "api": 0.03571428571428571, "par_id": 358, "authors": "Na", "prox_focus": 0.042450539483469149, "text_after": "\\section{Study 2 - Inquiry-based Lab}\nThe need for developing a tool for designing non-survey type of experiments was identified in Study 1. Therefore, we developed a proof-of-concept tool to support the design of one psychology paradigm - IAT. The tool provides a scaffolding guide to help learners think about critical components of the IAT design (i.e. hypothesis, conditions, randomization, counterbalance, stimuli, and instruction). Scaffolding is an important technique in guiding inexperienced learners, especially in inquiry-based learning~\\cite{hmelo2007scaffolding}. We had two goals in Study 2: (1) because lab activity is still so rare in social science education, and there is no successful model to learn from, we designed the scaffolding guide model and we wanted to verify whether it can support students to successfully design experiments, (2) we wanted to understand whether combining classroom demonstration and inquiry-based lab is more beneficial than inquiry-based lab alone, in other words, whether the knowledge obtained from being subjects in experiments can transfer to be used in a new context, where learners apply that knowledge to design their own experiments. \n", "prox_user": 0.0}, "360": {"change_type": ["add"], "section_title": "Study 2 - Inquiry-based Lab", "text_before": "", "author": "01989413042403575936", "section_id": 13, "change_extent": 1.0, "focus": 0, "api": 0.017857142857142856, "par_id": 360, "authors": "Na", "prox_focus": 0.040507326688838892, "text_after": "\\subsection{Method}\nWe recruited 20 subjects from [University name anonymized] Psychology Department\u2019s subject pool. Because the study was conducted in summer, the subjects were mostly from the local community. 17 subjects were college students, 3 subjects were professional workers. Only 2 subjects majored in psychology, while other subjects\u2019 majors varied across a broad range of STEM (e.g., computer science, applied math) and humanities (e.g., music, French) degrees. Therefore, the subjects represent a wide range of novice learners with different backgrounds. ", "prox_user": 0.0}, "361": {"change_type": ["add"], "section_title": "Study 2 - Inquiry-based Lab", "text_before": "", "author": "01989413042403575936", "section_id": 13, "change_extent": 1.0, "focus": 0, "api": 0.017857142857142856, "par_id": 361, "authors": "Na", "prox_focus": 0.040507326688838892, "text_after": "The study has three phases: (1) learners read a one page learning material about IAT, (2) learners participate in some IATs and see their results, (3) learners think about a new hypothesis and design an IAT to test that hypothesis. Subjects were interviewed afterwards about their learning process and their experience with the tool. The task lasted about one hour and half, and subjects were compensated \\$15 each. ", "prox_user": 0.0}, "362": {"change_type": ["add"], "section_title": "Study 2 - Inquiry-based Lab", "text_before": "", "author": "01989413042403575936", "section_id": 13, "change_extent": 1.0, "focus": 0, "api": 0.017857142857142856, "par_id": 362, "authors": "Na", "prox_focus": 0.040507326688838892, "text_after": "To understand how subject experience affects learning, we measured each individual\u2019s IAT score in Phase 2. The IAT score measurement is similar to effect size measurement based on differences between means, detailed technique can be found in \\cite{greenwald2003understanding}. Basically, the IAT measurement calculates the differences between two conditions, the larger the differences are, the more prejudice the subject is. Learning is measured by the quality of the IATs that subjects designed in Phase 3. Two raters independently rated each IAT\\footnote{The rubrics can be found online at http://tiny.cc/g1tu3x}. Interrater agreement was high (cronback\u2019s alpha = .957). We averaged the ratings into one single score to represent the quality of an IAT design. The score ranges from 0 to 5, the higher the score, the better learning the subject achieves. We also probed subject experience in the interview, the analysis method is the same as Study 1.\n", "prox_user": 0.0}, "363": {"change_type": ["add", "edit", "edit"], "section_title": "Results and Discussions", "text_before": "", "author": "01989413042403575936", "section_id": 12, "change_extent": 1, "focus": 0, "api": 0.04081632653061224, "par_id": 363, "authors": "Na", "prox_focus": 0.05027378671436155, "text_after": "\\subsection{Results and Discussions}\nThirteen learners (65\\% of the subjects) designed new IATs, seven learners did not finish the task. We challenged our design with learners who had no or little social science background and we asked gave them limited time to learn to design psychology experiments, this result is already a good sign that the design is workable.\n", "prox_user": 0.0}, "364": {"change_type": ["add", "edit"], "section_title": "Subject experience and learning transfer", "text_before": "", "author": "01989413042403575936", "section_id": 13, "change_extent": 1, "focus": 0, "api": 0.028061224489795915, "par_id": 364, "authors": "Na", "prox_focus": 0.061161749881173733, "text_after": "\\subsubsection{Subject experience and learning transfer}\nWe analyzed the relationship between \\textit{IAT score} and \\textit{rating of IAT design} using linear regression. \\textit{IAT score} had significant effect on \\textit{rating of IAT design} (p \\textless .05, R\\textsuperscript{2} = .47). This result shows that people who have more prejudice are more likely to design better IATs. This interpretation is clearly not generalizable beyond this learning task, however we can also interpret the result as people who have more intensive subject experience are more likely to design better experiments. Essentially, because the calculation of the IAT score captures the contrast between conditions, which is also the main effect that subjects are to experience, the IAT score actually reflects the intensity of subjects\u2019 experience. It seems that the knowledge learners obtained from being subjects in experiments can transfer to be used when they learn to design experiments. Learners\u2019 comments from the interview confirmed our inference. For example, ``[Talking about taking an IAT] I understand the contrast between the two [conditions], it\u2019s obvious.\u2019\u2019, ``It was easy to sort of base it off of the one I took, because you just think about two contrast concepts, A or not A, or B or not B. It was really easy to make it.\u2019\u2019", "prox_user": 0.0}, "366": {"change_type": ["add"], "section_title": "Study 2 - Inquiry-based Lab", "text_before": "", "author": "01989413042403575936", "section_id": 13, "change_extent": 1.0, "focus": 0, "api": 0.02551020408163265, "par_id": 366, "authors": "Na", "prox_focus": 0.041011727240540308, "text_after": "\\subsubsection{Scaffolding guide vs. No guide}\nScaffolding guide emphasizes critical components in experimental design, learners had mixed response to the design. Most learners appreciate that they could learn concepts of experimental design from the guide while doing it, ``Even if you took the experiment, it\u2019s not like you did understand the conceptual process like how it was set up. The guide made it way easy to design my experiment.\u2019\u2019 But, learners also brought up the issue that they could not map the frame they saw when taking the experiment to the guide when designing experiments. For example,``It may be easier if you saw it and you moved the thing, or put it on the frame as it would be read.\u2019\u2019", "prox_user": 0.0}, "367": {"change_type": ["add"], "section_title": "Study 2 - Inquiry-based Lab", "text_before": "", "author": "01989413042403575936", "section_id": 13, "change_extent": 1.0, "focus": 0, "api": 0.02551020408163265, "par_id": 367, "authors": "Na", "prox_focus": 0.041011727240540308, "text_after": "\\textbf{Implication:} Scaffolding guide supports novice learners to learn experimental design during the design process. However, it needs to be designed carefully so that it work with not against learners\u2019 subject experience. ", "prox_user": 0.0}, "371": {"change_type": ["add", "edit"], "section_title": "Participating in an experiment and Analyzing your own data", "text_before": "", "author": "01989413042403575936", "section_id": 16, "change_extent": 1, "focus": 0, "api": 0.033163265306122444, "par_id": 371, "authors": "Na", "prox_focus": 0.049222609356725087, "text_after": "\\subsection{Participating in an experiment and Analyzing your own data}\nTELLab supports the best practice classroom demonstrations identified in our social science classrooms, including supporting students to participate in online experiments, see the three sets of results, and analyze their results trial by trial.\n", "prox_user": 0.0}, "372": {"change_type": ["add"], "section_title": "TELLab", "text_before": "", "author": "01989413042403575936", "section_id": 18, "change_extent": 1.0, "focus": 0, "api": 0.015306122448979591, "par_id": 372, "authors": "Na", "prox_focus": 0.045720220296850807, "text_after": "Suppose an instructor wants to teach prejudice and the method of measuring prejudice, the instructor can creates a TELLab lab for the course, and then students can enroll in the lab with the unique lab ID given by the instructor. The TELLab lab is a place for the instructor to manage experiments and monitor students\u2019 learning progress. ", "prox_user": 0.0}, "373": {"change_type": ["add"], "section_title": "TELLab", "text_before": "", "author": "01989413042403575936", "section_id": 18, "change_extent": 1.0, "focus": 0, "api": 0.015306122448979591, "par_id": 373, "authors": "Na", "prox_focus": 0.045720220296850807, "text_after": "Suppose the instructor has created an IAT that tests gender bias in occupation, now the instructor can add the test to the lab. In the physical classroom, the instructor asks students to log into their online lab. Students will see a list of experiments in the lab, they click the gender bias IAT for that week, which will take them to the IAT page to participate. The IAT experiment looks like the first picture in Figure~\\ref{fig:experiments}. Students will be instructed to use the LEFT and RIGHT arrow key to make choices, after that they will see a result page, which looks like Figure~\\ref{fig:result1}. Once the instructor sees that most of the students have accomplished the test, the instructor can click a button to see the class result page and show it to students. ", "prox_user": 0.0}, "374": {"change_type": ["add"], "section_title": "TELLab", "text_before": "", "author": "01989413042403575936", "section_id": 18, "change_extent": 1.0, "focus": 0, "api": 0.022959183673469385, "par_id": 374, "authors": "Na", "prox_focus": 0.034057002074770422, "text_after": "Students own their data stored in their TELLab account. After accomplishing an experiment, students can download their data in CSV format. The data is stored in two forms, wide form and long form. Instructors and students can flexibly choose their favorite form to analyze the data. In wide form each row is about one subject\u2019s result and each column is about a piece of information (such as response time, accuracy) of a trial plus some columns containing the experiment and subject information:\\\\\n{\\scriptsize \\texttt{[resultId] [participantId] [groupId] [timestamp] [demographic field1, field2, field3, \u2026] [frame1\\char`_[Id,name,content,responseKey,responseTime,accuracy], frame2\\char`_[Id,name,content,responseKey,responseTime,accuracy], frame3\\char`_[Id,name,content,responseKey,responseTime,accuracy], ...]}}", "prox_user": 0.0}, "375": {"change_type": ["add"], "section_title": "TELLab", "text_before": "", "author": "01989413042403575936", "section_id": 18, "change_extent": 1.0, "focus": 0, "api": 0.022959183673469385, "par_id": 375, "authors": "Na", "prox_focus": 0.034057002074770422, "text_after": "\\subsubsection{Classroom demonstrations from social psychology to neuroscience}\nWhat range of experiments do TELLab support? Behavioral experiments can be designed in hundreds of thousands of forms. They range from simple surveys mostly using text to highly interactive animated experiments with images and videos (often used in neuroscience). On the other hand, many experiments share common elements, for example, multiple choice questions are always consist of one question and some options, IATs are always consist of five tasks with the third task and the fourth task being two contrast conditions, and each condition is consist of two contrast concept pairs. Inspired by this observation, we did not design experiments individually, we design experiment templates and users can use the templates to generate many experiments (discussed in detail in the next section). Figure~\\ref{fig:experiments} depicts some examples of TELLab experiments, they are generated by different templates, the presentation and types of data collected from each experiment are very different. Many TELLab templates are designed with Phaser (phaser.io) - a game engine written in JavaScript. Because Phaser has a load stage to prepare each scene (in our case each trial) before loading, it avoids loading delay and therefore ensures millisecond accuracy of reaction time. Phaser also supports modeling of physical interactions, which powers some most interactive cognitive experiments online, such as multiple object tracking.  ", "prox_user": 0.0}, "376": {"change_type": ["add"], "section_title": "TELLab", "text_before": "", "author": "01989413042403575936", "section_id": 18, "change_extent": 1.0, "focus": 0, "api": 0.022959183673469385, "par_id": 376, "authors": "Na", "prox_focus": 0.034057002074770422, "text_after": "\\subsection{Replicating an experiment and Designing your own}\n", "prox_user": 0.0}, "377": {"change_type": ["add"], "section_title": "TELLab", "text_before": "", "author": "01989413042403575936", "section_id": 18, "change_extent": 1.0, "focus": 0, "api": 0.022959183673469385, "par_id": 377, "authors": "Na", "prox_focus": 0.034057002074770422, "text_after": "\\subsubsection{Basic experiment design activity}\nSuppose a student wants to verify an experiment design that was done in classroom demonstration. She can click a button to make a copy of that experiment into her account or she can model it off and create one from scratch. Suppose the student wants to modify a gender IAT. Designing a new one using the IAT scaffolding guide is equally easy as modifying an existing one. Figure~\\ref{fig:template} shows the first step in the guide, where it asks her to provide two contrast concepts. The only difference between creating a new IAT and modifying an existing IAT is whether the two contrast concepts exist in the input box.", "prox_user": 0.0}, "378": {"change_type": ["add", "edit"], "section_title": "Basic experiment design activity", "text_before": "", "author": "01989413042403575936", "section_id": 20, "change_extent": 1, "focus": 0, "api": 0.033163265306122444, "par_id": 378, "authors": "Na", "prox_focus": 0.037412451904711062, "text_after": "In the following example, modifying an existing experiment is easier. Again, suppose a student wants to modify an experiment. The experiment contains 120 trials, each trial contains an image, subjects are asked to type a key to proceed to the next trial. The layout of the experiment (trial-by-trial) looks like the first picture in Figure~\\ref{fig:modify}. In this case, there is no scaffolding guide, the whole experiment design only uses general modules, such as block, html, and image, as seen in the second picture in Figure~\\ref{fig:modify}. She only wants to change the stimuli and its response key of a certain trial. Although she can still create the whole experiment from scratch, it is actually easier to copy over the experiment into her account and just modify that single trial. She can change the stimuli, and she can change how the trial proceeds to the next trial. \n", "prox_user": 0.0}, "251": {"change_type": ["edit", "edit", "edit", "edit", "edit"], "section_title": "Method", "text_before": "\\subsection{Data analysis}\nWe analyzed the data using the grounded theory methods         ~\\cite{corbin2014basics, muller2014curiosity} through an iterative process of                open coding, axial coding, and selective coding            . We started analyzing data after 2 interviews were completed, and continued    analyzing each new transcript as we completed it. We revisited and reanalyzed all data when a new concept emerged from a new transcript.                                                                 ", "author": "01989413042403575936", "section_id": 8, "change_extent": 0.60199886181009254, "focus": 0, "api": 0.28826530612244894, "par_id": 251, "authors": "Na", "prox_focus": 0.028517767566125521, "text_after": "\\subsection{Method}\nWe recruited 13 students from the three classes. We conducted semi-structured interview with each student to understand (1) what are students\u2019 experience in these classroom demonstrations, (2) why do students engage or not engage in classroom demonstrations, (3) what are the perceived learning outcomes. Each interview lasted about an hour, students were compensated with \\$15 each. We analyzed the data through an iterative process of open coding, axial coding, and selective coding. In the open coding stage, we interpreted the data with an ``open mind\u2019\u2019~\\cite{muller2014curiosity}, only using one or two words that best described conceptually the meaning of that data. In the axial coding stage, we analyzed the relationships among the codes as they emerged and generated relevant concepts. In the selective coding stage, we integrated the core concepts emerged from the axial coding into a grounded model to describe the social and environmental factors that impacted students\u2019 experience and learning in classroom demonstrations.\n", "prox_user": 0.032563954212295125}, "380": {"change_type": ["add"], "section_title": "TELLab", "text_before": "", "author": "01989413042403575936", "section_id": 18, "change_extent": 1.0, "focus": 0, "api": 0.012755102040816325, "par_id": 380, "authors": "Na", "prox_focus": 0.055129219774371734, "text_after": "In TELLab, a new experiment template is a standalone JavaScript file in the following form:\\\\\n{\\scriptsize \\texttt{Tellab.modules.modulename(function() \\{ }}\\\\\n\\phantom{xxx}{\\scriptsize \\texttt{var \\textcolor{ForestGreen}{parameter1} = function() \\{ }}\\\\\n\\phantom{xxx}{\\scriptsize \\texttt{ //render scaffolding guide in TELLab experiment editor }}\\\\\n\\phantom{xxxxxxxx}{\\scriptsize \\texttt{ ... }}\\\\\n\\phantom{xxx}{\\scriptsize \\texttt{ //define a listener to collect parameter1 from inputs in the guide }}\\\\\n\\phantom{xxxxxxxx}{\\scriptsize \\texttt{ ... }}\\\\\n\\phantom{xxx}{\\scriptsize \\texttt{ \\} }}\\\\\n\\phantom{xxx}{\\scriptsize \\texttt{ ... }}\\\\\n\\phantom{xxx}{\\scriptsize \\texttt{return \\{ }}\\\\\n\\phantom{xxxxxxxx}{\\scriptsize \\texttt{\\textcolor{ForestGreen}{parameter1}, }}\\\\\n\\phantom{xxxxxxxx}{\\scriptsize \\texttt{ ... }}\\\\\n{\\scriptsize \\texttt{\\} )() }}\\\\", "prox_user": 0.0}, "381": {"change_type": ["add"], "section_title": "TELLab", "text_before": "", "author": "01989413042403575936", "section_id": 18, "change_extent": 1.0, "focus": 0, "api": 0.012755102040816325, "par_id": 381, "authors": "Na", "prox_focus": 0.055129219774371734, "text_after": "For TELLab to know how to set up a trial to run given a list of parameters, she has to provide a function in the following form:\\\\\n{\\scriptsize \\texttt{var modulename = function() \\{ }}\\\\\n\\phantom{xxx}{\\scriptsize \\texttt{var keys = arguments[3], parameters = arguments[4]; }}\\\\\n\\phantom{xxx}{\\scriptsize \\texttt{\\textcolor{ForestGreen}{setupKeys();} }}\\\\\n\\phantom{xxx}{\\scriptsize \\texttt{\\textcolor{ForestGreen}{defineAnimation();} }}\\\\\n\\phantom{xxx}{\\scriptsize \\texttt{\\textcolor{ForestGreen}{setupKeyListener();} //define data to collect for the trial }}\\\\\n\\phantom{xxx}{\\scriptsize \\texttt{\\textcolor{ForestGreen}{proceedToNext();} }}\\\\\n{\\scriptsize \\texttt{ \\} }}\\\\", "prox_user": 0.0}, "382": {"change_type": ["add"], "section_title": "TELLab", "text_before": "", "author": "01989413042403575936", "section_id": 18, "change_extent": 1.0, "focus": 0, "api": 0.012755102040816325, "par_id": 382, "authors": "Na", "prox_focus": 0.055129219774371734, "text_after": "To demonstrate the use of the TELLab experiment template API, we implemented 8 experiment templates, including 4 general templates and 4 specialized templates. The general templates are Block, Html, Image, and Video. Block defines how to randomize and iterate trials, blocks can be nested in other blocks iteratively. Image and Video allows upload of images and videos and manipulation of the positions in a trial. The specialized templates are Implicit Association Test (IAT), Multiple Object Tracking (MOT), Visual Search, and Change Detection. The number of parameters of these templates range from 3 to 15, which enables many possibilities to vary the templates.", "prox_user": 0.0}}